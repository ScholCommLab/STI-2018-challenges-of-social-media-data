{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STI 2018 - DOIs, URLs, and FB\n",
    "\n",
    "Code to produce quantification of three problem cases with the WOS state_of_oa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "import itertools\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.1f}'.format\n",
    "\n",
    "input1 = \"data/crossref_100k_resolved.csv\"\n",
    "input2 = \"data/crossref_100k_full.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load resolved DOIs\n",
    "resolved_doi = pd.read_csv(input1, index_col=\"doi\")\n",
    "resolved_doi['domain'] = resolved_doi.resolved.map(lambda x: urlparse(x)[1] if pd.notnull(x) else None)\n",
    "resolved_doi['prefix'] = resolved_doi.index.map(lambda x: x.split(\"/\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOI Resolving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Articles</th>\n",
       "      <th>[%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Got response from crossref</th>\n",
       "      <td>86706</td>\n",
       "      <td>86.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Resolved with 200s</th>\n",
       "      <td>68743</td>\n",
       "      <td>68.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Resolved with error</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. RequestException + TimeOuts</th>\n",
       "      <td>13290</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5. Resolved to HTTPS</th>\n",
       "      <td>53437</td>\n",
       "      <td>53.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6. Resolved to HTTP</th>\n",
       "      <td>33269</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7. Duplicate URLs</th>\n",
       "      <td>313</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Articles  [%]\n",
       "1. Got response from crossref      86706 86.7\n",
       "2. Resolved with 200s              68743 68.7\n",
       "3. Resolved with error                 0  0.0\n",
       "4. RequestException + TimeOuts     13290 13.3\n",
       "5. Resolved to HTTPS               53437 53.4\n",
       "6. Resolved to HTTP                33269 33.3\n",
       "7. Duplicate URLs                    313  0.3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = len(resolved_doi)\n",
    "\n",
    "a = resolved_doi.status_code.notnull().sum()\n",
    "b = resolved_doi.status_code.value_counts()[200]\n",
    "c = len(resolved_doi[resolved_doi.status_code.notnull()]) - a\n",
    "d = resolved_doi.err.value_counts()['RequestException'] + resolved_doi.err.value_counts()['Timeout']\n",
    "\n",
    "https_urls = resolved_doi.resolved.map(lambda x: x[4] == \"s\" if pd.notnull(x) else None).sum()\n",
    "http_urls = resolved_doi.resolved.notnull().sum()-https_urls\n",
    "\n",
    "dupl = resolved_doi[resolved_doi.resolved.notnull()].resolved.duplicated(keep=False).sum()\n",
    "\n",
    "out = pd.DataFrame.from_dict({\n",
    "    \"1. Got response from crossref\":[a,a*100/l],\n",
    "    \"2. Resolved with 200s\":[b,b*100/l],\n",
    "    \"3. Resolved with error\":[c,c*100/l],\n",
    "    \"4. RequestException + TimeOuts\":[d,d*100/l],\n",
    "    \"5. Resolved to HTTPS\": [https_urls, https_urls*100/l],\n",
    "    \"6. Resolved to HTTP\": [http_urls, http_urls*100/l],\n",
    "    \"7. Duplicate URLs\": [dupl, dupl*100/l]\n",
    "}, orient='index')\n",
    "out.columns = ['Articles', '[%]']\n",
    "out.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 - URL Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big 5 DOIs: 45575 (45.6%)\n",
      "Samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://linkinghub.elsevier.com/retrieve/pii/S0002939499004158',\n",
       " 'https://link.springer.com/article/10.1007%2FBF00306977',\n",
       " 'https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1440-1746.2005.04155.x',\n",
       " 'http://www.tandfonline.com/doi/full/10.1517/14712598.2012.679654',\n",
       " 'http://journals.sagepub.com/doi/10.1177/103841629300200107']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_5 = ['linkinghub.elsevier.com',\n",
    "         'link.springer.com',\n",
    "         'onlinelibrary.wiley.com',\n",
    "         'www.tandfonline.com',\n",
    "         'journals.sagepub.com']\n",
    "\n",
    "ind = []\n",
    "for d in big_5:\n",
    "    ind.append(resolved_doi[resolved_doi.domain == d].sample().index[0])\n",
    "    \n",
    "a = len(resolved_doi[resolved_doi.domain.isin(big_5)])\n",
    "print(\"Big 5 DOIs: {} ({:.1f}%)\".format(a, 100*a/l))\n",
    "\n",
    "print(\"Samples\")\n",
    "resolved_doi.loc[ind][['status_code', 'resolved', 'domain', 'prefix']].resolved.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consts\n",
    "ids = ['ogid'+str(i) for i in range (1,5)]\n",
    "eng = ['eng'+str(i) for i in range (1,5)]\n",
    "urls = ['url'+str(i) for i in range (1,5)]\n",
    "# shares = ['shares1','shares2','shares3','shares4']\n",
    "\n",
    "dtype={}\n",
    "for i in range(1,5):\n",
    "    dtype['url'+str(i)] = str\n",
    "    dtype['og_eng'+str(i)] = str\n",
    "    dtype['og_obj'+str(i)] = str\n",
    "    dtype['og_err'+str(i)] = str\n",
    "\n",
    "url_response = pd.read_csv(input2, index_col=\"doi\", parse_dates=['ts'], dtype=dtype)\n",
    "\n",
    "# Prepare results\n",
    "results = url_response[urls].copy()\n",
    "for i in range(1,5):\n",
    "    results['ogid'+str(i)] = url_response['og_obj'+str(i)].map(lambda x: json.loads(x)['id'] if pd.notnull(x) else None)\n",
    "    results['eng'+str(i)] = url_response['og_eng'+str(i)].map(lambda x: sum(json.loads(x).values()) if pd.notnull(x) else None)\n",
    "    #results['shares'+str(i)] = df['og_eng'+str(i)].map(lambda x: json.loads(x)['share_count'] if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = results[eng].apply(lambda x: sum(x) > 0, axis=1)\n",
    "results_eng = results[x]\n",
    "\n",
    "x = results[ids].apply(lambda x: x.notnull().sum() > 0, axis=1)\n",
    "results_ids = results[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP/HTTPS URL breakdown for articles with OG object or Eng>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENG</th>\n",
       "      <th>IDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>1659</td>\n",
       "      <td>9125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https</th>\n",
       "      <td>377</td>\n",
       "      <td>1301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ENG   IDS\n",
       "http   1659  9125\n",
       "https   377  1301"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_https_breakdown(df):\n",
    "    http = 0\n",
    "    https = 0\n",
    "    df = df[['url1', 'url2','ogid1', 'ogid2']]\n",
    "    for row in df.itertuples():\n",
    "        if row[3]:\n",
    "            if row[1][4] == \"s\":\n",
    "                https = https + 1\n",
    "            else:\n",
    "                http = http + 1\n",
    "        if row[4]:\n",
    "            if row[2][4] == \"s\":\n",
    "                https = https + 1\n",
    "            else:\n",
    "                http = http + 1\n",
    "    return {'http':http, 'https':https}\n",
    "pd.DataFrame({'IDS':get_https_breakdown(results_ids),\n",
    "              'ENG':get_https_breakdown(results_eng)}, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage of 4 URL variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENG</th>\n",
       "      <th>ENG (%)</th>\n",
       "      <th>IDS</th>\n",
       "      <th>IDS (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1099</td>\n",
       "      <td>1.3</td>\n",
       "      <td>5727</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>807</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4699</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>588</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3834</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ENG  ENG (%)   IDS  IDS (%)\n",
       "0  1099      1.3  5727      6.6\n",
       "1   807      0.9  4699      5.4\n",
       "2    10      0.0    49      0.1\n",
       "3   588      0.7  3834      4.4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov = results[ids].apply(lambda x: x.notnull().sum()).values\n",
    "cov_eng = results[eng].apply(lambda x: sum(x>0)).values\n",
    "pd.DataFrame({'IDS':cov,\n",
    "              'IDS (%)':cov/(len(results)/100),\n",
    "              'ENG':cov_eng,\n",
    "              'ENG (%)': cov_eng/(len(results)/100)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 - DOI shares spread across graph objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pairs(row):\n",
    "    ids = ['1', '2', '3', '4']\n",
    "    \n",
    "    atleastonematching = False\n",
    "    for c in itertools.combinations(ids, 2):\n",
    "        x = c[0]\n",
    "        y = c[1]\n",
    "        \n",
    "        # if one of the Ob_IDs is empty, move on\n",
    "        if row['ogid' + x] is None or row['ogid' + y] is None:\n",
    "            continue\n",
    "\n",
    "        # keep track of matching Ob_IDs\n",
    "        if row['ogid' + x] == row['ogid' + y]:\n",
    "            atleastonematching = True\n",
    "\n",
    "            # if we have matching IDs, but non matching values, it is a problem\n",
    "            if row['eng' + x] != row['eng' + y]:\n",
    "                return False\n",
    "    \n",
    "    if atleastonematching:\n",
    "        return True\n",
    "\n",
    "    return None\n",
    "\n",
    "def check_nonmatching(row):\n",
    "    ids = ['1', '2', '3', '4']\n",
    "    \n",
    "    for c in itertools.combinations(ids, 2):\n",
    "        x = c[0]\n",
    "        y = c[1]\n",
    "        \n",
    "        # if one of the Ob_IDs is empty, move on\n",
    "        if row['ogid' + x] is None or row['ogid' + y] is None:\n",
    "            continue\n",
    "        \n",
    "        if row['ogid' + x] != row['ogid' + y]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def prepare_sub_df(df, n):\n",
    "    x = df[ids].apply(lambda x: x.notnull().sum() == n, axis=1)\n",
    "    return df[x].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.23it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 14.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numbers</th>\n",
       "      <th>Not matching IDs</th>\n",
       "      <th>Matching IDs, Matching Shares</th>\n",
       "      <th>Matching IDs, Mismatching Shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One ID</th>\n",
       "      <td>1447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two IDs</th>\n",
       "      <td>542</td>\n",
       "      <td>229</td>\n",
       "      <td>176</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three IDs</th>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four IDs</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Numbers  Not matching IDs  Matching IDs, Matching Shares  \\\n",
       "Zero            65                 0                              0   \n",
       "One ID        1447                 0                              0   \n",
       "Two IDs        542               229                            176   \n",
       "Three IDs       41                33                             22   \n",
       "Four IDs         1                 0                              0   \n",
       "\n",
       "           Matching IDs, Mismatching Shares  \n",
       "Zero                                      0  \n",
       "One ID                                    0  \n",
       "Two IDs                                 137  \n",
       "Three IDs                                10  \n",
       "Four IDs                                  0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf = results_eng\n",
    "\n",
    "subdfs = []\n",
    "for i in tqdm(range(0, 5), total=5):\n",
    "    subdfs.append(prepare_sub_df(tdf, i))\n",
    "\n",
    "nonmatch_indices=[]\n",
    "ts = []\n",
    "fs = []\n",
    "nms = []\n",
    "counts = []\n",
    "    \n",
    "for df in tqdm(subdfs):\n",
    "    df['check_pairs'] = df.apply(check_pairs, axis=1)\n",
    "    x = df.groupby('check_pairs')\n",
    "    try:\n",
    "        ts.append(x.size().loc[True])\n",
    "        fs.append(x.size().loc[False])\n",
    "    except:\n",
    "        ts.append(0)\n",
    "        fs.append(0)\n",
    "    nms.append(df.apply(check_nonmatching, axis=1).sum())\n",
    "    counts.append(len(df))\n",
    "\n",
    "    nonmatch_indices.extend(df[df['check_pairs']==False].index.tolist())\n",
    "\n",
    "cols = ['Numbers', 'Not matching IDs', 'Matching IDs, Matching Shares', 'Matching IDs, Mismatching Shares']\n",
    "pd.DataFrame({cols[0]:counts,\n",
    "              cols[1]:nms,\n",
    "              cols[2]:ts,\n",
    "              cols[3]:fs,},\n",
    "             index=[\"Zero\",\"One ID\",\"Two IDs\",\"Three IDs\",\"Four IDs\"])[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.62s/it]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numbers</th>\n",
       "      <th>Not matching IDs</th>\n",
       "      <th>Matching IDs, Matching Shares</th>\n",
       "      <th>Matching IDs, Mismatching Shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One ID</th>\n",
       "      <td>10274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two IDs</th>\n",
       "      <td>1630</td>\n",
       "      <td>582</td>\n",
       "      <td>911</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three IDs</th>\n",
       "      <td>257</td>\n",
       "      <td>57</td>\n",
       "      <td>236</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four IDs</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Numbers  Not matching IDs  Matching IDs, Matching Shares  \\\n",
       "One ID       10274                 0                              0   \n",
       "Two IDs       1630               582                            911   \n",
       "Three IDs      257                57                            236   \n",
       "Four IDs         1                 0                              0   \n",
       "\n",
       "           Matching IDs, Mismatching Shares  \n",
       "One ID                                    0  \n",
       "Two IDs                                 137  \n",
       "Three IDs                                10  \n",
       "Four IDs                                  0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf = results_ids\n",
    "\n",
    "subdfs = []\n",
    "for i in tqdm(range(1, 5), total=4):\n",
    "    subdfs.append(prepare_sub_df(tdf, i))\n",
    "\n",
    "nonmatch_indices=[]\n",
    "ts = []\n",
    "fs = []\n",
    "nms = []\n",
    "counts = []\n",
    "    \n",
    "for df in tqdm(subdfs):\n",
    "    df['check_pairs'] = df.apply(check_pairs, axis=1)\n",
    "    x = df.groupby('check_pairs')\n",
    "    try:\n",
    "        ts.append(x.size().loc[True])\n",
    "        fs.append(x.size().loc[False])\n",
    "    except:\n",
    "        ts.append(0)\n",
    "        fs.append(0)\n",
    "    nms.append(df.apply(check_nonmatching, axis=1).sum())\n",
    "    counts.append(len(df))\n",
    "\n",
    "    nonmatch_indices.extend(df[df['check_pairs']==False].index.tolist())\n",
    "\n",
    "cols = ['Numbers', 'Not matching IDs', 'Matching IDs, Matching Shares', 'Matching IDs, Mismatching Shares']\n",
    "pd.DataFrame({cols[0]:counts,\n",
    "              cols[1]:nms,\n",
    "              cols[2]:ts,\n",
    "              cols[3]:fs,},\n",
    "             index=[\"One ID\",\"Two IDs\",\"Three IDs\",\"Four IDs\"])[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 - Same OG IDs across different articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate ids: 26\n",
      "Number of articles affected: 343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asura/.virtualenvs/altmetrics/lib/python3.5/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "df = results_ids[ids].copy()\n",
    "\n",
    "df['all_ids'] = df[ids].apply(lambda x: [int(y) for y in set(x) if pd.notnull(y)], axis=1)\n",
    "all_ids = df.all_ids.sum()\n",
    "counter = collections.Counter(all_ids)\n",
    "\n",
    "dup_ids = set([i for (i,v) in counter.items() if v > 1])\n",
    "print(\"Number of duplicate ids: %s\" % len(dup_ids))\n",
    "\n",
    "results_ids['has_dup'] = df.all_ids.map(lambda x: len(dup_ids.intersection(x)) > 0)\n",
    "print(\"Number of articles affected: %s\" % results_ids.has_dup.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of 3 problem cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolved_doi['problem_1'] = resolved_doi.resolved.isnull()\n",
    "resolved_doi['problem_2'] = resolved_doi.merge(results_ids[['has_dup']], how=\"left\", left_index=True, right_index=True)['has_dup']\n",
    "resolved_doi['problem_3'] = None\n",
    "resolved_doi.loc[nonmatch_indices, 'problem_3'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problem_1   13,294.0\n",
       "problem_2      343.0\n",
       "problem_3      148.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolved_doi[['problem_1', 'problem_2', 'problem_3']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem case 1, 2, and 3 among all articles: 13705 (13.7%)\n",
      "Problem case 2, and 3 among articles w/ eng: 345 (16.5%)\n"
     ]
    }
   ],
   "source": [
    "a = resolved_doi[['problem_1', 'problem_2', 'problem_3']].apply(lambda x: x.any(), axis=1).sum()\n",
    "b = resolved_doi.loc[results_eng.index][['problem_2', 'problem_3']].apply(lambda x: x.any(), axis=1).sum()\n",
    "\n",
    "print(\"Problem case 1, 2, and 3 among all articles: {} ({:.1f}%)\".format(a, 100*a/len(resolved_doi)))\n",
    "print(\"Problem case 2, and 3 among articles w/ eng: {} ({:.1f}%)\".format(b, 100*b/len(results_eng)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altmetrics",
   "language": "python",
   "name": "altmetrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
