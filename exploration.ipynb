{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STI 2018 - DOIs, URLs, and FB\n",
    "\n",
    "Code to produce quantification of three problem cases with the WOS state_of_oa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "import itertools\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.1f}'.format\n",
    "\n",
    "input1 = \"data/wos_100k_resolved.csv\"\n",
    "input2 = \"data/wos_100k_full.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load resolved DOIs\n",
    "resolved_doi = pd.read_csv(input1, index_col=\"doi\")\n",
    "resolved_doi['domain'] = resolved_doi.resolved.map(lambda x: urlparse(x)[1] if pd.notnull(x) else None)\n",
    "resolved_doi['prefix'] = resolved_doi.index.map(lambda x: x.split(\"/\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOI Resolving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Articles</th>\n",
       "      <th>[%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Got response from crossref</th>\n",
       "      <td>91490</td>\n",
       "      <td>88.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Resolved with 200s</th>\n",
       "      <td>85515</td>\n",
       "      <td>82.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Resolved with error</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. RequestException + TimeOuts</th>\n",
       "      <td>12049</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5. Resolved to HTTPS</th>\n",
       "      <td>69619</td>\n",
       "      <td>67.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6. Resolved to HTTP</th>\n",
       "      <td>21871</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7. Duplicate URLs</th>\n",
       "      <td>68</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Articles  [%]\n",
       "1. Got response from crossref      91490 88.4\n",
       "2. Resolved with 200s              85515 82.6\n",
       "3. Resolved with error                 0  0.0\n",
       "4. RequestException + TimeOuts     12049 11.6\n",
       "5. Resolved to HTTPS               69619 67.2\n",
       "6. Resolved to HTTP                21871 21.1\n",
       "7. Duplicate URLs                     68  0.1"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = len(resolved_doi)\n",
    "\n",
    "a = resolved_doi.status_code.notnull().sum()\n",
    "b = resolved_doi.status_code.value_counts()[200]\n",
    "c = len(resolved_doi[resolved_doi.status_code.notnull()]) - a\n",
    "d = resolved_doi.err.value_counts()['RequestException'] + resolved_doi.err.value_counts()['Timeout']\n",
    "\n",
    "https_urls = resolved_doi.resolved.map(lambda x: x[4] == \"s\" if pd.notnull(x) else None).sum()\n",
    "http_urls = resolved_doi.resolved.notnull().sum()-https_urls\n",
    "\n",
    "dupl = resolved_doi[resolved_doi.resolved.notnull()].resolved.duplicated(keep=False).sum()\n",
    "\n",
    "out = pd.DataFrame.from_dict({\n",
    "    \"1. Got response from crossref\":[a,a*100/l],\n",
    "    \"2. Resolved with 200s\":[b,b*100/l],\n",
    "    \"3. Resolved with error\":[c,c*100/l],\n",
    "    \"4. RequestException + TimeOuts\":[d,d*100/l],\n",
    "    \"5. Resolved to HTTPS\": [https_urls, https_urls*100/l],\n",
    "    \"6. Resolved to HTTP\": [http_urls, http_urls*100/l],\n",
    "    \"7. Duplicate URLs\": [dupl, dupl*100/l]\n",
    "}, orient='index')\n",
    "out.columns = ['Articles', '[%]']\n",
    "out.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 - URL Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big 5 DOIs: 55777 (53.9%)\n",
      "Samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://linkinghub.elsevier.com/retrieve/pii/S1549963414003256',\n",
       " 'https://link.springer.com/article/10.1007%2Fs10337-010-1883-4',\n",
       " 'https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.909',\n",
       " 'https://www.tandfonline.com/doi/full/10.1179/1743282014Y.0000000119',\n",
       " 'http://journals.sagepub.com/doi/10.1177/1010539513486919']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_5 = ['linkinghub.elsevier.com',\n",
    "         'link.springer.com',\n",
    "         'onlinelibrary.wiley.com',\n",
    "         'www.tandfonline.com',\n",
    "         'journals.sagepub.com']\n",
    "\n",
    "ind = []\n",
    "for d in big_5:\n",
    "    ind.append(df[df.domain == d].sample().index[0])\n",
    "    \n",
    "a = len(df[df.domain.isin(big_5)])\n",
    "print(\"Big 5 DOIs: {} ({:.1f}%)\".format(a, 100*a/l))\n",
    "\n",
    "print(\"Samples\")\n",
    "df.loc[ind][['status_code', 'resolved', 'domain', 'prefix']].resolved.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consts\n",
    "ids = ['ogid'+str(i) for i in range (1,5)]\n",
    "eng = ['eng'+str(i) for i in range (1,5)]\n",
    "urls = ['url'+str(i) for i in range (1,5)]\n",
    "# shares = ['shares1','shares2','shares3','shares4']\n",
    "\n",
    "dtype={}\n",
    "for i in range(1,5):\n",
    "    dtype['url'+str(i)] = str\n",
    "    dtype['og_eng'+str(i)] = str\n",
    "    dtype['og_obj'+str(i)] = str\n",
    "    dtype['og_err'+str(i)] = str\n",
    "\n",
    "url_response = pd.read_csv(input2, index_col=\"doi\", parse_dates=['ts'], dtype=dtype)\n",
    "\n",
    "# Prepare results\n",
    "results = url_response[urls].copy()\n",
    "for i in range(1,5):\n",
    "    results['ogid'+str(i)] = url_response['og_obj'+str(i)].map(lambda x: json.loads(x)['id'] if pd.notnull(x) else None)\n",
    "    results['eng'+str(i)] = url_response['og_eng'+str(i)].map(lambda x: sum(json.loads(x).values()) if pd.notnull(x) else None)\n",
    "    #results['shares'+str(i)] = df['og_eng'+str(i)].map(lambda x: json.loads(x)['share_count'] if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = results[eng].apply(lambda x: sum(x) > 0, axis=1)\n",
    "results_eng = results[x]\n",
    "\n",
    "x = results[ids].apply(lambda x: x.notnull().sum() > 0, axis=1)\n",
    "results_ids = results[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP/HTTPS URL breakdown for articles with OG object or Eng>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENG</th>\n",
       "      <th>IDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>3821</td>\n",
       "      <td>19901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https</th>\n",
       "      <td>684</td>\n",
       "      <td>1856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ENG    IDS\n",
       "http   3821  19901\n",
       "https   684   1856"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_https_breakdown(df):\n",
    "    http = 0\n",
    "    https = 0\n",
    "    df = df[['url1', 'url2','ogid1', 'ogid2']]\n",
    "    for row in df.itertuples():\n",
    "        if row[3]:\n",
    "            if row[1][4] == \"s\":\n",
    "                https = https + 1\n",
    "            else:\n",
    "                http = http + 1\n",
    "        if row[4]:\n",
    "            if row[2][4] == \"s\":\n",
    "                https = https + 1\n",
    "            else:\n",
    "                http = http + 1\n",
    "    return {'http':http, 'https':https}\n",
    "pd.DataFrame({'IDS':get_https_breakdown(results_ids),\n",
    "              'ENG':get_https_breakdown(results_eng)}, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage of 4 URL variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENG</th>\n",
       "      <th>ENG (%)</th>\n",
       "      <th>IDS</th>\n",
       "      <th>IDS (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1426</td>\n",
       "      <td>1.6</td>\n",
       "      <td>8452</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2458</td>\n",
       "      <td>2.7</td>\n",
       "      <td>13305</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>0.1</td>\n",
       "      <td>179</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2612</td>\n",
       "      <td>2.9</td>\n",
       "      <td>10124</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ENG  ENG (%)    IDS  IDS (%)\n",
       "0  1426      1.6   8452      9.2\n",
       "1  2458      2.7  13305     14.5\n",
       "2    74      0.1    179      0.2\n",
       "3  2612      2.9  10124     11.1"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov = results[ids].apply(lambda x: x.notnull().sum()).values\n",
    "cov_eng = results[eng].apply(lambda x: sum(x>0)).values\n",
    "pd.DataFrame({'IDS':cov,\n",
    "              'IDS (%)':cov/(len(results)/100),\n",
    "              'ENG':cov_eng,\n",
    "              'ENG (%)': cov_eng/(len(results)/100)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 - DOI shares spread across graph objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pairs(row):\n",
    "    ids = ['1', '2', '3', '4']\n",
    "    \n",
    "    atleastonematching = False\n",
    "    for c in itertools.combinations(ids, 2):\n",
    "        x = c[0]\n",
    "        y = c[1]\n",
    "        \n",
    "        # if one of the Ob_IDs is empty, move on\n",
    "        if row['ogid' + x] is None or row['ogid' + y] is None:\n",
    "            continue\n",
    "\n",
    "        # keep track of matching Ob_IDs\n",
    "        if row['ogid' + x] == row['ogid' + y]:\n",
    "            atleastonematching = True\n",
    "\n",
    "            # if we have matching IDs, but non matching values, it is a problem\n",
    "            if row['eng' + x] != row['eng' + y]:\n",
    "                return False\n",
    "    \n",
    "    if atleastonematching:\n",
    "        return True\n",
    "\n",
    "    return None\n",
    "\n",
    "def check_nonmatching(row):\n",
    "    ids = ['1', '2', '3', '4']\n",
    "    \n",
    "    for c in itertools.combinations(ids, 2):\n",
    "        x = c[0]\n",
    "        y = c[1]\n",
    "        \n",
    "        # if one of the Ob_IDs is empty, move on\n",
    "        if row['ogid' + x] is None or row['ogid' + y] is None:\n",
    "            continue\n",
    "        \n",
    "        if row['ogid' + x] != row['ogid' + y]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def prepare_sub_df(df, n):\n",
    "    x = df[ids].apply(lambda x: x.notnull().sum() == n, axis=1)\n",
    "    return df[x].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.14s/it]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numbers</th>\n",
       "      <th>Not matching IDs</th>\n",
       "      <th>Matching IDs, Matching Shares</th>\n",
       "      <th>Matching IDs, Mismatching Shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zero</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One ID</th>\n",
       "      <td>3687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two IDs</th>\n",
       "      <td>1535</td>\n",
       "      <td>769</td>\n",
       "      <td>620</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three IDs</th>\n",
       "      <td>161</td>\n",
       "      <td>131</td>\n",
       "      <td>99</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four IDs</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Numbers  Not matching IDs  Matching IDs, Matching Shares  \\\n",
       "Zero           106                 0                              0   \n",
       "One ID        3687                 0                              0   \n",
       "Two IDs       1535               769                            620   \n",
       "Three IDs      161               131                             99   \n",
       "Four IDs         9                 8                              6   \n",
       "\n",
       "           Matching IDs, Mismatching Shares  \n",
       "Zero                                      0  \n",
       "One ID                                    0  \n",
       "Two IDs                                 146  \n",
       "Three IDs                                43  \n",
       "Four IDs                                  3  "
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf = results_eng\n",
    "\n",
    "subdfs = []\n",
    "for i in tqdm(range(0, 5), total=5):\n",
    "    subdfs.append(prepare_sub_df(tdf, i))\n",
    "\n",
    "nonmatch_indices=[]\n",
    "ts = []\n",
    "fs = []\n",
    "nms = []\n",
    "counts = []\n",
    "    \n",
    "for df in tqdm(subdfs):\n",
    "    df['check_pairs'] = df.apply(check_pairs, axis=1)\n",
    "    x = df.groupby('check_pairs')\n",
    "    try:\n",
    "        ts.append(x.size().loc[True])\n",
    "        fs.append(x.size().loc[False])\n",
    "    except:\n",
    "        ts.append(0)\n",
    "        fs.append(0)\n",
    "    nms.append(df.apply(check_nonmatching, axis=1).sum())\n",
    "    counts.append(len(df))\n",
    "\n",
    "    nonmatch_indices.extend(df[df['check_pairs']==False].index.tolist())\n",
    "\n",
    "cols = ['Numbers', 'Not matching IDs', 'Matching IDs, Matching Shares', 'Matching IDs, Mismatching Shares']\n",
    "pd.DataFrame({cols[0]:counts,\n",
    "              cols[1]:nms,\n",
    "              cols[2]:ts,\n",
    "              cols[3]:fs,},\n",
    "             index=[\"Zero\",\"One ID\",\"Two IDs\",\"Three IDs\",\"Four IDs\"])[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:19<00:00,  4.77s/it]\n",
      "100%|██████████| 4/4 [00:03<00:00,  1.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numbers</th>\n",
       "      <th>Not matching IDs</th>\n",
       "      <th>Matching IDs, Matching Shares</th>\n",
       "      <th>Matching IDs, Mismatching Shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One ID</th>\n",
       "      <td>21768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two IDs</th>\n",
       "      <td>4739</td>\n",
       "      <td>1694</td>\n",
       "      <td>2899</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three IDs</th>\n",
       "      <td>258</td>\n",
       "      <td>207</td>\n",
       "      <td>191</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four IDs</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Numbers  Not matching IDs  Matching IDs, Matching Shares  \\\n",
       "One ID       21768                 0                              0   \n",
       "Two IDs       4739              1694                           2899   \n",
       "Three IDs      258               207                            191   \n",
       "Four IDs        10                 9                              7   \n",
       "\n",
       "           Matching IDs, Mismatching Shares  \n",
       "One ID                                    0  \n",
       "Two IDs                                 146  \n",
       "Three IDs                                43  \n",
       "Four IDs                                  3  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf = results_ids\n",
    "\n",
    "subdfs = []\n",
    "for i in tqdm(range(1, 5), total=4):\n",
    "    subdfs.append(prepare_sub_df(tdf, i))\n",
    "\n",
    "nonmatch_indices=[]\n",
    "ts = []\n",
    "fs = []\n",
    "nms = []\n",
    "counts = []\n",
    "    \n",
    "for df in tqdm(subdfs):\n",
    "    df['check_pairs'] = df.apply(check_pairs, axis=1)\n",
    "    x = df.groupby('check_pairs')\n",
    "    try:\n",
    "        ts.append(x.size().loc[True])\n",
    "        fs.append(x.size().loc[False])\n",
    "    except:\n",
    "        ts.append(0)\n",
    "        fs.append(0)\n",
    "    nms.append(df.apply(check_nonmatching, axis=1).sum())\n",
    "    counts.append(len(df))\n",
    "\n",
    "    nonmatch_indices.extend(df[df['check_pairs']==False].index.tolist())\n",
    "\n",
    "cols = ['Numbers', 'Not matching IDs', 'Matching IDs, Matching Shares', 'Matching IDs, Mismatching Shares']\n",
    "pd.DataFrame({cols[0]:counts,\n",
    "              cols[1]:nms,\n",
    "              cols[2]:ts,\n",
    "              cols[3]:fs,},\n",
    "             index=[\"One ID\",\"Two IDs\",\"Three IDs\",\"Four IDs\"])[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 - Same OG IDs across different articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate ids: 66\n",
      "Number of articles affected: 507\n"
     ]
    }
   ],
   "source": [
    "df = results_ids[ids].copy()\n",
    "\n",
    "df['all_ids'] = df[ids].apply(lambda x: [int(y) for y in set(x) if pd.notnull(y)], axis=1)\n",
    "all_ids = df.all_ids.sum()\n",
    "counter = collections.Counter(all_ids)\n",
    "\n",
    "dup_ids = set([i for (i,v) in counter.items() if v > 1])\n",
    "print(\"Number of duplicate ids: %s\" % len(dup_ids))\n",
    "\n",
    "results_ids['has_dup'] = df.all_ids.map(lambda x: len(dup_ids.intersection(x)) > 0)\n",
    "print(\"Number of articles affected: %s\" % results_ids.has_dup.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of 3 problem cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'a':[1,2,3,4,5,6]})\n",
    "test2 = pd.DataFrame({'b':[True, None, None, False]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a      b\n",
       "0  1   True\n",
       "1  2   None\n",
       "2  3   None\n",
       "3  4  False\n",
       "4  5    NaN\n",
       "5  6    NaN"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.merge(test2, how=\"left\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolved_doi['problem_1'] = resolved_doi.resolved.isnull()\n",
    "resolved_doi['problem_2'] = resolved_doi.merge(results_ids[['has_dup']], how=\"left\", left_index=True, right_index=True)['has_dup']\n",
    "resolved_doi['problem_3'] = None\n",
    "resolved_doi.loc[nonmatch_indices, 'problem_3'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problem_1   12,049.0\n",
       "problem_2      507.0\n",
       "problem_3      192.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolved_doi[['problem_1', 'problem_2', 'problem_3']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem case 1, 2, and 3 among all articles: 12722 (12.3%)\n",
      "Problem case 2, and 3 among articles w/ eng: 648 (11.8%)\n"
     ]
    }
   ],
   "source": [
    "a = resolved_doi[['problem_1', 'problem_2', 'problem_3']].apply(lambda x: x.any(), axis=1).sum()\n",
    "b = resolved_doi.loc[results_eng.index][['problem_2', 'problem_3']].apply(lambda x: x.any(), axis=1).sum()\n",
    "\n",
    "print(\"Problem case 1, 2, and 3 among all articles: {} ({:.1f}%)\".format(a, 100*a/len(resolved_doi)))\n",
    "print(\"Problem case 2, and 3 among articles w/ eng: {} ({:.1f}%)\".format(b, 100*b/len(results_eng)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting DOIs\n",
    "\n",
    "**10.1007/s00586-013-2675-y**\n",
    "\n",
    "Same OG ID for http/https but different one for DOI. Different share numbers\n",
    "\n",
    "**10.1038/nature13893**\n",
    "\n",
    "Different OG objects\n",
    "\n",
    "**10.7717/peerj.794**\n",
    "\n",
    "Same share numbers, different OG IDs\n",
    "\n",
    "**10.1016/j.aap.2014.03.007**\n",
    "\n",
    "Elsevier redirect page, various OG IDs\n",
    "\n",
    "**10.7440/res53.2015.10**\n",
    "\n",
    "Various IDs across DOI, URL\n",
    "\n",
    "## Used code\n",
    "\n",
    "```\n",
    "doi = '10.7440/res53.2015.10'\n",
    "rec = df.loc[doi]\n",
    "urls = [rec.url, rec.url2, \"https://doi.org/%s\" % doi, \"http://dx.doi.org/%s\" % doi]\n",
    "pprint(fb_queries(urls))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem with missing scraped data\n",
    "\n",
    "Results for the http and https for journals.ametsoc.org/doi/abs/10.1175/JAS-D-12-0315.1 \n",
    "\n",
    "URL    | OG ID            | Shares | Date (scrape)\n",
    "-------|------------------|--------|---------------\n",
    "HTTP   | 685490234864647  | 2      | September 30, 2016\n",
    "HTTPS  | None             | None   | None\n",
    "\n",
    "After manually triggering a rescrape:\n",
    "\n",
    "URL    | OG ID            | Shares | Date (scrape)\n",
    "-------|------------------|--------|---------------\n",
    "HTTP   | 1818366768210382 | 0      | March 28, 2018\n",
    "HTTPS  | 1818366768210382 | 0      | March 28, 2018\n",
    "\n",
    "Apparently shares associated with previous canonical URLs are lost..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altmetrics",
   "language": "python",
   "name": "altmetrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
